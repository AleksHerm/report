---
title: "Automated Interpretation of Metrics and Effect Sizes"
output: 
  github_document:
    toc: true
    fig_width: 10.08
    fig_height: 6
  rmarkdown::html_vignette:
    toc: true
    fig_width: 10.08
    fig_height: 6
tags: [r, report, effect size, rules of thumb, guidelines, interpretation]
vignette: >
  \usepackage[utf8]{inputenc}
editor_options: 
  chunk_output_type: console
bibliography: bibliography.bib
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  tidy.opts=list(width.cutoff=60),
  tidy=TRUE,
  fig.path = "README-"
)
options(knitr.kable.NA = '',
        digits = 4)
```


## Why?

The metrics used in statistics (indices of fit, model performance or parameter estimates) can be very abstract. A long experience is required to intuitively ***"feel"*** the meaning of their values. In order to facilitate the understanding of the results they are facing, many scientists use (often implicitly) some set of **rules of thumb**. Thus, in order to validate and standardize such interpretation grids, some authors validated and published them in the form of guidelines. One of the most famous interpertation grid was proposed by **Cohen (1988)** for a series of widely used indices, such as the correlation **r** (*r* = .20, small; *r* = .40, moderate and *r* = .60, large) or the **standardized difference** (*Cohen's d*). 

The package **`report`** implements such sets of rules of thumb for a variety of indices in a flexible and explicit fashion, helping you understanding and reporting your results in a scientific yet meaningful way. However, readers should keep in mind that these thresholds, altough *"validated"*, **remain arbitrary**. Thus, their use should be discussed on a case-by-case basis depending on the field, hypotheses, prior results and so on, to avoid their crystalisation, as for the infamous ***p* < .05** example.



## Supported Indices

### Coefficient of determination  (R2)


#### @falk1992primer

```r
interpret_r2(x, rules = "falk1992")
```

- **R2 < 0.1**: Negligible
- **R2 > 0.1**: Adequate



#### @cohen1988statistical

```r
interpret_r2(x, rules = "cohen1988")
```

- **R2 = 0 - 0.02**: Very weak
- **R2 = 0.02 - 0.16**: Weak
- **R2 = 0.16 - 0.26**: Moderate
- **R2 > 0.26**: Substantial




#### @chin1998partial

```r
interpret_r2(x, rules = "chin1998")
```

- **R2 = 0 - 0.19**: Very weak
- **R2 = 0.19 - 0.33**: Weak
- **R2 = 0.33 - 0.67**: Moderate
- **R2 > 0.67**: Substantial

#### @hair2011pls

```r
interpret_r2(x, rules = "hair2011")
```

- **R2 = 0 - 0.25**: Very weak
- **R2 = 0.25 - 0.50**: Weak
- **R2 = 0.50 - 0.75**: Moderate
- **R2 > 0.75**: Substantial



### Correlation *r*



#### @gignac2016effect

```r
interpret_r(x, rules = "gignac2016")
```

- **r = 0 - 0.1**: Very small
- **r = 0.1 - 0.2**: Small 
- **r = 0.2 - 0.3**: Moderate ("typical")
- **r > 0.3**: Large



#### @cohen1988statistical

```r
interpret_r(x, rules = "cohen1988")
```

- **r = 0 - 0.1**: Very small
- **r = 0.1 - 0.3**: Small
- **r = 0.3 - 0.5**: Moderate
- **r > 0.5**: Large


#### @evans1996straightforward

```r
interpret_r(x, rules = "evans1996")
```

- **r = 0 - 0.2**: Very weak
- **r = 0.2 - 0.4**: Weak
- **r = 0.4 - 0.6**: Moderate
- **r = 0.6 - 0.8**: Strong
- **r > 0.8**: Very strong



### Standardized Difference *d* (Cohen's *d*)

The sandardized difference can be obtained through the standardization of linear model's parameters or data, in which they can be used as indices of effect size.


#### @cohen1988statistical

```r
interpret_d(x, rules = "cohen1988")
```

- **d = 0 - 0.2**: Very small
- **d = 0.2 - 0.5**: Small
- **d = 0.5 - 0.8**: Medium
- **d > 0.8**: Large

#### @sawilowsky2009new

```r
interpret_d(x, rules = "sawilowsky2009")
```

- **d = 0 - 0.1**: Tiny
- **d = 0.1 - 0.2**: Very small
- **d = 0.2 - 0.5**: Small
- **d = 0.5 - 0.8**: Medium
- **d = 0.8 - 1.2**: Large
- **d = 1.2 - 2**: Very large
- **d > 2**: Huge


### Odds ratio

Odds ratio, and *log* odds ratio, are often found in epidemiological studies. However, they are also the parameters of ***logistic*** regressions, where they can be used as indices of effect size.

#### @chen2010big

```r
interpret_odds(x, rules = "chen2010")
```

- **d = 0 - 1.68**: Very small
- **d = 1.68 - 3.47**: Small
- **d = 3.47 - 6.71**: Medium
- **d > 6.71**: Large

#### @cohen1988statistical

```r
interpret_odds(x, rules = "cohen1988")
```

This converts (log) odds ratio to standardized difference *d* using the following formula [@cohen1988statistical;@sanchez2003effect]:

```r
d <- log_odds * (sqrt(3) / pi)
```


### Omega Squared


The Omega squared is a measure of effect size used in ANOVAs. It is an estimate of how much variance in the response variables are accounted for by the explanatory variables. Omega squared is widely viewed as a lesser biased alternative to eta-squared, especially when sample sizes are small.

#### @field2013discovering

```r
interpret_omega_squared(x, rules = "field2013")
```

- **Omega Squared = 0 - 0.01**: Very small
- **Omega Squared = 0.01 - 0.06**: Small
- **Omega Squared = 0.06 - 0.14**: Medium
- **Omega Squared > 0.14**: Large




### Bayes Factor (BF)

The Bayes Factor if a useful measure of evidence against or in favour of a hypothesis. Note that **BFs** between 0 and 1, indicating evidence *against* the hypothesis, are converted via `bf = 1 / abs(bf)`.


#### @jeffreys1961theory

```r
interpret_bf(x, rules = "jeffreys1961")
```

- **bf = 1 - 3**: Anecdotal
- **bf = 3 - 10**: Moderate
- **bf = 10 - 30**: Strong
- **bf = 30 - 100**: Very strong
- **bf > 100**: Extreme

#### @raftery1995bayesian

```r
interpret_bf(x, rules = "raftery1995")
```

- **bf = 1 - 3**: Weak
- **bf = 3 - 20**: Positive
- **bf = 20 - 150**: Strong
- **bf > 150**: Very strong




### Bayesian Convergence Diagnostic (Rthat and Effective Sample Size)


Experts have suggested thresholds value to help interpreting and convergence and sampling quality. As such, `Rhat` should not be larger than 1.1 [@gelman1992inference] or 1.01 [@vehtari2019rank]. An `effective sample size` (ESS) greater than 1,000 is sufficient for stable estimates [@burkner2017brms].


### Other Bayesian Indices (\% in ROPE, *pd*)


The interpretation of Bayesian indices is detailed in [this article](https://easystats.github.io/bayestestR/articles/4_Guidelines.html).



## References